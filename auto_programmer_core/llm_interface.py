# auto_programmer_core/llm_interface.py
# LLMæ¥å£æ¨¡å—

import logging
import json
import re
from abc import ABC, abstractmethod
from typing import Dict, Any, Union
import time
import random

# å°è¯•å¯¼å…¥ google.genai
try:
    from google import genai as user_specific_google_genai_sdk
    from google.genai import errors as genai_errors
    logging.getLogger(__name__).info("æˆåŠŸå¯¼å…¥ 'google.genai' åŠå…¶é”™è¯¯å¤„ç†æ¨¡å—ã€‚")
except ImportError:
    logging.getLogger(__name__).critical("å…³é”®é”™è¯¯ï¼šæ— æ³•ä» 'google' å¯¼å…¥ 'genai'ã€‚è¯·ç¡®ä¿ç›¸å…³Google AIåº“å·²å®‰è£…ã€‚")
    user_specific_google_genai_sdk = None
    genai_errors = None

logger = logging.getLogger(__name__)

class AbstractLLMProvider(ABC):
    """
    LLMæä¾›è€…çš„æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰äº†æ‰€æœ‰æä¾›è€…å¿…é¡»å®ç°çš„æ¥å£ã€‚
    """
    @abstractmethod
    def generate_response(self, prompt_text: str, **kwargs) -> str:
        """
        å‘LLMå‘é€Promptå¹¶è·å–çº¯æ–‡æœ¬å›å¤ã€‚
        """
        pass

class GeminiProvider(AbstractLLMProvider):
    """
    ä½¿ç”¨Google Gemini APIçš„LLMæä¾›è€…å®ç°ã€‚
    """
    def __init__(self, api_key: str, model_name: str, max_retries: int = 3):
        if not api_key:
            raise ValueError("Gemini APIå¯†é’¥ä¸èƒ½ä¸ºç©ºã€‚")
        self.model_name = model_name
        self.max_retries = max_retries
        if user_specific_google_genai_sdk is None or genai_errors is None:
            raise ImportError("ç”±äº 'google.genai' SDKæœªèƒ½å¯¼å…¥, æ— æ³•åˆå§‹åŒ–GeminiProviderã€‚")
        try:
            self.client = user_specific_google_genai_sdk.Client(api_key=api_key)
            logger.info(f"GeminiProvider åˆå§‹åŒ–æˆåŠŸã€‚é…ç½®æ¨¡å‹: {self.model_name}")
        except Exception as e:
            raise ConnectionError(f"åˆ›å»º 'google.genai.Client' å®ä¾‹æ—¶å‘ç”Ÿé”™è¯¯: {e}") from e

    def generate_response(self, prompt_text: str, **kwargs) -> str:
        last_exception = None
        for attempt in range(self.max_retries):
            try:
                response = self.client.models.generate_content(
                    model=self.model_name, 
                    contents=prompt_text
                )
                if hasattr(response, 'text') and response.text:
                    logger.info("æˆåŠŸä»Geminiè·å–å›å¤ã€‚")
                    return response.text
                else:
                    last_exception = RuntimeError("Gemini API æœªè¿”å›æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹ã€‚")
                    time.sleep(5)
                    continue
            except genai_errors.ResourceExhaustedError as e:
                last_exception = e
                wait_time = (2 ** attempt) * 15 + random.uniform(0, 1)
                logger.warning(f"è§¦å‘APIé€Ÿç‡é™åˆ¶ (429)ã€‚ç¬¬ {attempt + 1}/{self.max_retries} æ¬¡å°è¯•ã€‚å°†åœ¨ {wait_time:.2f} ç§’åé‡è¯•ã€‚")
                print(f"âš ï¸  æ£€æµ‹åˆ°APIè¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åœ¨ {int(wait_time)} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                continue
            except Exception as e:
                logger.error(f"ä¸Gemini API äº¤äº’æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                raise RuntimeError(f"Gemini API è°ƒç”¨å¤±è´¥: {e}") from e
        raise RuntimeError(f"Gemini API è°ƒç”¨åœ¨ {self.max_retries} æ¬¡é‡è¯•åæœ€ç»ˆå¤±è´¥: {last_exception}") from last_exception


class LLMInterface:
    """
    LLMæ¥å£ç±»ï¼Œä½œä¸ºä¸LLMæä¾›è€…äº¤äº’çš„ç»Ÿä¸€å…¥å£ï¼Œå¹¶å¢åŠ äº†å“åº”å¤„ç†èƒ½åŠ›ã€‚
    """
    def __init__(self, llm_config: dict):
        self.provider_type = llm_config.get("provider", "gemini").lower()
        self.provider_config = llm_config
        self.provider: AbstractLLMProvider = self._create_provider()
        logger.info(f"LLMInterface åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ {self.provider_type} æä¾›è€…ã€‚")

    def _create_provider(self) -> AbstractLLMProvider:
        if self.provider_type == "gemini":
            api_key = self.provider_config.get("api_key")
            model_name = self.provider_config.get("model_name")
            if not api_key or not model_name:
                raise ValueError("Gemini APIå¯†é’¥å’Œæ¨¡å‹åç§°å¿…é¡»åœ¨é…ç½®ä¸­æä¾›ã€‚")
            return GeminiProvider(api_key=api_key, model_name=model_name)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›è€…ç±»å‹: {self.provider_type}")
    
    def _clean_json_response(self, text: str) -> str:
        """
        ã€å·²é‡æ„ã€‘æ¸…ç†LLMè¿”å›çš„å¯èƒ½åŒ…å«Markdownæ ‡è®°æˆ–æ ¼å¼é”™è¯¯çš„JSONå­—ç¬¦ä¸²ã€‚
        æ­¤å‡½æ•°ç°åœ¨å¯ä»¥å¤„ç†å­—ç¬¦ä¸²å­—é¢é‡ä¸­æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦ï¼Œè¿™æ˜¯å¯¼è‡´è§£æå¤±è´¥çš„ä¸»è¦åŸå› ã€‚
        """
        # 1. ç§»é™¤Markdownä»£ç å—æ ‡è®°
        match = re.search(r"```(json)?\s*([\s\S]*?)\s*```", text, re.DOTALL)
        if match:
            content = match.group(2).strip()
        else:
            content = text.strip()

        # 2. ä¿®æ­£æ ¸å¿ƒé—®é¢˜ï¼šå¤„ç†å­—ç¬¦ä¸²å­—é¢é‡ä¸­æœªè½¬ä¹‰çš„ç‰¹æ®Šå­—ç¬¦
        # è¿™æ˜¯ä¸€ä¸ªæ›´å¥å£®çš„æ–¹æ³•ï¼Œå®ƒä¼šéå†å­—ç¬¦ä¸²ï¼Œè·Ÿè¸ªæ˜¯å¦åœ¨å­—ç¬¦ä¸²å­—é¢é‡å†…éƒ¨ï¼Œ
        # å¹¶ä¸”åªåœ¨å†…éƒ¨æ—¶è½¬ä¹‰æ¢è¡Œç¬¦ç­‰ç‰¹æ®Šå­—ç¬¦ã€‚
        escaped_content = []
        in_string = False
        is_escaped = False

        for char in content:
            # å¦‚æœå‰ä¸€ä¸ªå­—ç¬¦æ˜¯è½¬ä¹‰ç¬¦ '\'ï¼Œåˆ™å½“å‰å­—ç¬¦ä¸ä½œä¸ºç‰¹æ®Šå­—ç¬¦å¤„ç†
            if is_escaped:
                escaped_content.append(char)
                is_escaped = False
                continue

            # é‡åˆ°è½¬ä¹‰ç¬¦
            if char == '\\':
                is_escaped = True
                escaped_content.append(char)
                continue

            # é‡åˆ°åŒå¼•å·ï¼Œåˆ‡æ¢ "åœ¨å­—ç¬¦ä¸²å†…/å¤–" çš„çŠ¶æ€
            if char == '"':
                in_string = not in_string

            # æ ¸å¿ƒé€»è¾‘ï¼šå¦‚æœåœ¨å­—ç¬¦ä¸²å†…éƒ¨ä¸”é‡åˆ°æ¢è¡Œç¬¦æˆ–åˆ¶è¡¨ç¬¦ï¼Œåˆ™è¿›è¡Œè½¬ä¹‰
            if in_string and char == '\n':
                escaped_content.append('\\n')
            elif in_string and char == '\t':
                escaped_content.append('\\t')
            else:
                escaped_content.append(char)
        
        return "".join(escaped_content)

    def generate_response(self, prompt: str, expect_json: bool = False, **kwargs) -> Union[str, Dict[str, Any]]:
        """
        é€šè¿‡å·²é…ç½®çš„LLMæä¾›è€…å‘é€Promptå¹¶è·å–å›å¤ã€‚
        å¦‚æœ expect_json ä¸º Trueï¼Œåˆ™å°è¯•å°†å›å¤è§£æä¸ºJSONå­—å…¸ã€‚
        """
        logger.info(f"LLMInterface å‡†å¤‡å‘ {self.provider_type} æä¾›è€…å‘é€Promptã€‚æœŸæœ›JSON: {expect_json}")
        print("ğŸ¤– æ­£åœ¨ä¸AIè¿›è¡Œæ·±åº¦æ²Ÿé€šï¼Œè¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´ï¼Œè¯·ç¨å€™...")
        try:
            raw_response = self.provider.generate_response(prompt_text=prompt, **kwargs)

            if not expect_json:
                return raw_response
            
            cleaned_response = self._clean_json_response(raw_response)
            try:
                json_data = json.loads(cleaned_response)
                logger.info("æˆåŠŸå°†LLMçš„å›å¤è§£æä¸ºJSONã€‚")
                return json_data
            except json.JSONDecodeError as e:
                logger.error(f"è§£æLLMå“åº”ä¸ºJSONå¤±è´¥: {e}. åŸå§‹å›å¤(æ¸…ç†å): '{cleaned_response}'")
                return {
                    "error": "json_decode_error",
                    "message": str(e),
                    "original_response": raw_response
                }

        except Exception as e:
            logger.error(f"LLMInterface åœ¨è°ƒç”¨ provider.generate_response æ—¶æ•è·åˆ°é”™è¯¯: {e}")
            print(f"âŒ åœ¨ä¸AIæ²Ÿé€šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise